{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adolfoguimaraes/datascience/blob/main/code/07_laboratorio_classificacao_de_texto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYzSufRjVBn1"
      },
      "source": [
        "# Naive Bayes - Análise de Sentimento\n",
        "\n",
        "Para essa atividade vamos gerar uma modelo de análise de sentimento em inglês baseado em reviews retirados de 3 sites: Amazon, IMDb e Yelp. Essa base está disponível [neste link](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences). Mais detalhes podem ser encontrados no link ou no artigo de referência: *From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015*. \n",
        "\n",
        "A base possui um texto e para cada texto um sentimento sobre o conteúdo abordado no texto. Os sentimentos podem ser positivos (1) ou negativos (2). Foram coletados em média 500 textos para cada sentimento em cada base. \n",
        "\n",
        "A atividade consiste em construir uma modelo de aprendizagem para análise de sentimento em inglês. O primeiro passo foi carregar o Dataset de forma apropriada e em seguida construir a matriz de entrada para nosso algoritmo. As etapas do exercício juntamente com o que deve ser feito está descrito a seguir. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvpLnvwqVBn9"
      },
      "source": [
        "## Carregando o Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsQEgNvoVBn_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_amazon = pd.read_csv(\"../datasets/analise_de_sentimento/amazon_cells_labelled.txt\", \n",
        "                        sep=\"\\t\", header=None, names=['Text','Sentiment'])\n",
        "df_imdb = pd.read_csv(\"../datasets/analise_de_sentimento/imdb_labelled.txt\", \n",
        "                        sep=\"\\t\", header=None, names=['Text','Sentiment'])\n",
        "df_yelp = pd.read_csv(\"../datasets/analise_de_sentimento/yelp_labelled.txt\", \n",
        "                        sep=\"\\t\", header=None, names=['Text','Sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpRb-WQ7VBoB",
        "outputId": "9320a5b6-cdee-4c5f-bb20-a9632ee8b678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amazon dataset (1000, 2)\n",
            "IMDb dataset (748, 2)\n",
            "Yelp dataset (1000, 2)\n"
          ]
        }
      ],
      "source": [
        "print(\"Amazon dataset %s\" % str(df_amazon.shape))\n",
        "print(\"IMDb dataset %s\" % str(df_imdb.shape))\n",
        "print(\"Yelp dataset %s\" % str(df_yelp.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN2vo2DnVBoC",
        "outputId": "737600ce-b8bb-45fb-db5c-5806eb33beec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2748, 2)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "join_frames = [df_amazon, df_imdb, df_yelp]\n",
        "\n",
        "df_final_dataset = pd.concat(join_frames)\n",
        "\n",
        "df_final_dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5yxZHgMVBoD"
      },
      "source": [
        "## Construindo a base de dados\n",
        "\n",
        "A base de dados possui 2748 textos que foram classificados em dois sentimentos: negativo (0) e positivo (1). Construa uma base de dados apropriada para os testes. Divida a base em treino e teste (80% para treino e 20% para teste). A base de treinamento será utilizado para a construção do modelo e a de teste para o teste final do modelo construído. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hKBvGteVBoF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_final_dataset['Text'], \n",
        "                                                    df_final_dataset['Sentiment'], \n",
        "                                                    random_state=1,\n",
        "                                                    test_size=0.2\n",
        "                                                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AV2yhAZ8VBoG",
        "outputId": "b0af84b1-5c86-4628-d02f-3ed2883a59dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows in the total set: 2748\n",
            "Number of rows in the training set: 2198\n",
            "Number of rows in the test set: 550\n"
          ]
        }
      ],
      "source": [
        "print('Number of rows in the total set: {}'.format(df_final_dataset.shape[0]))\n",
        "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
        "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuscUNZdVBoH"
      },
      "source": [
        "## Construindo o Bag of Words\n",
        "\n",
        "Construa o Bag of Words para a base de treinamento. Para isso, utilize o método CountVectorizer como mostrado a seguir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_fuw4XkVBoI",
        "outputId": "752b08cb-23bd-466b-a6d0-23fc28c88cd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vector = CountVectorizer()\n",
        "count_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzZfsAP6VBoL"
      },
      "source": [
        "O `CountVectorizer` permite construir o array que serve de entrada para os modelos de aprendizagem. O código a seguir, visualiza o array. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrSWX6qYVBoN",
        "outputId": "2ec78427-c260-4dbe-c543-195b5ae5c5ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2198, 4581)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data = count_vector.fit_transform(X_train)\n",
        "training_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIWtzT2MVBoO"
      },
      "source": [
        "Foi gerada uma matriz de 2198 linhas (os textos) e 4581 colunas (as palavras). Devemos fazer o mesmo com a base de teste. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJtZBylSVBoP",
        "outputId": "a7e9d653-a2d6-4288-8521-bd9dfebc81da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(550, 4581)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testing_data = count_vector.transform(X_test)\n",
        "testing_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2FPsFssVBoQ"
      },
      "source": [
        "Foi gerada uma matriz com 550 linhas e 4581 colunas também. `training_data` e `testing_data` são as estruturas que devem ser utilizadas no modelo Naive Bayes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC-jDD96VBoS"
      },
      "source": [
        "## Atividade 1\n",
        "\n",
        "Implemente um modelo Naive Bayes para a base gerada. Utilize validação cruzada de 5 folds na base de treinamento e em seguida teste o modelo gerado na base de testes. Reporte a acurácia resultante da validação cruzada e da base de testes. Teste os 3 tipos de Naive Bayes presentes no `scikit-learn`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DR-vEcerVBoT"
      },
      "outputs": [],
      "source": [
        "# Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctdWD0GFVBoV"
      },
      "source": [
        "### Atividade 2\n",
        "\n",
        "O Naive Bayes em si não tem muitos parâmetros para ajustar. No entanto, podemos ajustar no pré-processamento. Quando utilizamos a classe `CountVectorizer` podemos utilizar uma série de técnicas de pré-processamento para melhorar os dados de entrada do modelo. \n",
        "\n",
        "Pesquise sobre o `CountVectorizer` e modifique os parâmetros `default` para gerar dados melhores e, consequentemente, um modelo melhor do que o construído na Atividade 1. Reporte seus resultados na validação cruzada e nos testes. Utilize somente o tipo de Naive Bayes que teve melhor resultado na atividade 1. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN3OSUCTVBoW"
      },
      "outputs": [],
      "source": [
        "# Insert your code here"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "07_laboratorio_classificacao_de_texto.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}