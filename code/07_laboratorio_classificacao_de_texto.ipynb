{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adolfoguimaraes/datascience/blob/main/code/07_laboratorio_classificacao_de_texto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYzSufRjVBn1"
      },
      "source": [
        "# Naive Bayes - Análise de Sentimento\n",
        "\n",
        "Para essa atividade vamos gerar uma modelo de análise de sentimento em inglês baseado em reviews retirados de 3 sites: Amazon, IMDb e Yelp. Essa base está disponível [neste link](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences). Mais detalhes podem ser encontrados no link ou no artigo de referência: *From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015*. \n",
        "\n",
        "A base possui um texto e para cada texto um sentimento sobre o conteúdo abordado no texto. Os sentimentos podem ser positivos (1) ou negativos (2). Foram coletados em média 500 textos para cada sentimento em cada base. \n",
        "\n",
        "A atividade consiste em construir uma modelo de aprendizagem para análise de sentimento em inglês. O primeiro passo foi carregar o Dataset de forma apropriada e em seguida construir a matriz de entrada para nosso algoritmo. As etapas do exercício juntamente com o que deve ser feito está descrito a seguir. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvpLnvwqVBn9"
      },
      "source": [
        "## Carregando o Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YsQEgNvoVBn_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_amazon = pd.read_csv(\"../datasets/analise_de_sentimento/amazon_cells_labelled.txt\", \n",
        "                        sep=\"\\t\", header=None, names=['Text','Sentiment'])\n",
        "df_imdb = pd.read_csv(\"../datasets/analise_de_sentimento/imdb_labelled.txt\", \n",
        "                        sep=\"\\t\", header=None, names=['Text','Sentiment'])\n",
        "df_yelp = pd.read_csv(\"../datasets/analise_de_sentimento/yelp_labelled.txt\", \n",
        "                        sep=\"\\t\", header=None, names=['Text','Sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>The screen does get smudged easily because it ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>What a piece of junk.. I lose more calls on th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Item Does Not Match Picture.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The only thing that disappoint me is the infra...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>You can not answer calls with the unit, never ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Text  Sentiment\n",
              "0    So there is no way for me to plug it in here i...          0\n",
              "1                          Good case, Excellent value.          1\n",
              "2                               Great for the jawbone.          1\n",
              "3    Tied to charger for conversations lasting more...          0\n",
              "4                                    The mic is great.          1\n",
              "..                                                 ...        ...\n",
              "995  The screen does get smudged easily because it ...          0\n",
              "996  What a piece of junk.. I lose more calls on th...          0\n",
              "997                       Item Does Not Match Picture.          0\n",
              "998  The only thing that disappoint me is the infra...          0\n",
              "999  You can not answer calls with the unit, never ...          0\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_amazon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cpRb-WQ7VBoB",
        "outputId": "9320a5b6-cdee-4c5f-bb20-a9632ee8b678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amazon dataset (1000, 2)\n",
            "IMDb dataset (748, 2)\n",
            "Yelp dataset (1000, 2)\n"
          ]
        }
      ],
      "source": [
        "print(\"Amazon dataset %s\" % str(df_amazon.shape))\n",
        "print(\"IMDb dataset %s\" % str(df_imdb.shape))\n",
        "print(\"Yelp dataset %s\" % str(df_yelp.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VN2vo2DnVBoC",
        "outputId": "737600ce-b8bb-45fb-db5c-5806eb33beec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2748, 2)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "join_frames = [df_amazon, df_imdb, df_yelp]\n",
        "\n",
        "df_final_dataset = pd.concat(join_frames)\n",
        "\n",
        "df_final_dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5yxZHgMVBoD"
      },
      "source": [
        "## Construindo a base de dados\n",
        "\n",
        "A base de dados possui 2748 textos que foram classificados em dois sentimentos: negativo (0) e positivo (1). Construa uma base de dados apropriada para os testes. Divida a base em treino e teste (80% para treino e 20% para teste). A base de treinamento será utilizado para a construção do modelo e a de teste para o teste final do modelo construído. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9hKBvGteVBoF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_final_dataset['Text'], \n",
        "                                                    df_final_dataset['Sentiment'], \n",
        "                                                    random_state=1,\n",
        "                                                    test_size=0.2\n",
        "                                                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AV2yhAZ8VBoG",
        "outputId": "b0af84b1-5c86-4628-d02f-3ed2883a59dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows in the total set: 2748\n",
            "Number of rows in the training set: 2198\n",
            "Number of rows in the test set: 550\n"
          ]
        }
      ],
      "source": [
        "print('Number of rows in the total set: {}'.format(df_final_dataset.shape[0]))\n",
        "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
        "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuscUNZdVBoH"
      },
      "source": [
        "## Construindo o Bag of Words\n",
        "\n",
        "Construa o Bag of Words para a base de treinamento. Para isso, utilize o método CountVectorizer como mostrado a seguir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Q_fuw4XkVBoI",
        "outputId": "752b08cb-23bd-466b-a6d0-23fc28c88cd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vector = CountVectorizer()\n",
        "count_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzZfsAP6VBoL"
      },
      "source": [
        "O `CountVectorizer` permite construir o array que serve de entrada para os modelos de aprendizagem. O código a seguir, visualiza o array. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SrSWX6qYVBoN",
        "outputId": "2ec78427-c260-4dbe-c543-195b5ae5c5ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2198, 4581)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data = count_vector.fit_transform(X_train)\n",
        "training_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIWtzT2MVBoO"
      },
      "source": [
        "Foi gerada uma matriz de 2198 linhas (os textos) e 4581 colunas (as palavras). Devemos fazer o mesmo com a base de teste. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pJtZBylSVBoP",
        "outputId": "a7e9d653-a2d6-4288-8521-bd9dfebc81da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(550, 4581)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testing_data = count_vector.transform(X_test)\n",
        "testing_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2FPsFssVBoQ"
      },
      "source": [
        "Foi gerada uma matriz com 550 linhas e 4581 colunas também. `training_data` e `testing_data` são as estruturas que devem ser utilizadas no modelo Naive Bayes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC-jDD96VBoS"
      },
      "source": [
        "## Atividade 1\n",
        "\n",
        "Implemente um modelo de Machine Learning para a base gerada. Utilize validação cruzada de 5 folds na base de treinamento e em seguida teste o modelo gerado na base de testes. Reporte a acurácia resultante da validação cruzada e da base de testes. Teste pelo menos 3 algoritmos que possuem no`scikit-learn`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctdWD0GFVBoV"
      },
      "source": [
        "### Atividade 2\n",
        "\n",
        "Além dos parâmetros do algoritmos em si, podemos ajustar parâmetros do pré-processamento. Quando utilizamos a classe `CountVectorizer` podemos utilizar uma série de técnicas de pré-processamento para melhorar os dados de entrada do modelo. \n",
        "\n",
        "Pesquise sobre o `CountVectorizer` e modifique os parâmetros `default` para gerar dados melhores e, consequentemente, um modelo melhor do que o construído na Atividade 1. Reporte seus resultados na validação cruzada e nos testes. Reavalie os algoritmos e parâmetros testados na etapa 1 para verificar o que muda ao mudar a vetorização."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZN3OSUCTVBoW"
      },
      "outputs": [],
      "source": [
        "# Insira seu código a partir deste espaço."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "07_laboratorio_classificacao_de_texto.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
